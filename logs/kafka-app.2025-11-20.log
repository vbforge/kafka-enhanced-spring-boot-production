2025-11-20 19:20:39.453 [background-preinit] [] INFO  o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.3.Final
2025-11-20 19:20:39.490 [main] [] INFO  c.v.k.KafkaEnhancedApplication - Starting KafkaEnhancedApplication using Java 17.0.8 with PID 10704 (C:\Users\admin\Desktop\COMPLETE\kafka-enhanced-spring-boot-production\target\classes started by admin in C:\Users\admin\Desktop\COMPLETE\kafka-enhanced-spring-boot-production)
2025-11-20 19:20:39.493 [main] [] DEBUG c.v.k.KafkaEnhancedApplication - Running with Spring Boot v3.5.7, Spring v6.2.12
2025-11-20 19:20:39.493 [main] [] INFO  c.v.k.KafkaEnhancedApplication - No active profile set, falling back to 1 default profile: "default"
2025-11-20 19:20:40.428 [main] [] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8080 (http)
2025-11-20 19:20:40.436 [main] [] INFO  o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8080"]
2025-11-20 19:20:40.437 [main] [] INFO  o.a.catalina.core.StandardService - Starting service [Tomcat]
2025-11-20 19:20:40.437 [main] [] INFO  o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.48]
2025-11-20 19:20:40.474 [main] [] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
2025-11-20 19:20:40.474 [main] [] INFO  o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 952 ms
2025-11-20 19:20:40.665 [main] [] INFO  c.v.k.config.KafkaErrorHandlerConfig - ✅ Error Handler configured: 3 retries, 2s backoff, DLT enabled
2025-11-20 19:20:40.676 [main] [] INFO  c.v.k.metrics.KafkaMetricsService - ✅ Kafka metrics initialized
2025-11-20 19:20:41.080 [main] [] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 5 endpoints beneath base path '/actuator'
2025-11-20 19:20:41.145 [main] [] INFO  o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8080"]
2025-11-20 19:20:41.156 [main] [] INFO  o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8080 (http) with context path '/'
2025-11-20 19:20:41.184 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dlt-consumer-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dlt-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:20:41.228 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:20:41.288 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:20:41.288 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:20:41.288 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763659241285
2025-11-20 19:20:41.296 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dlt-consumer-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dlt-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:20:41.297 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:20:41.302 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:20:41.303 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:20:41.303 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763659241302
2025-11-20 19:20:41.305 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dlt-consumer-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dlt-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:20:41.305 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:20:41.309 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:20:41.309 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:20:41.309 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763659241309
2025-11-20 19:20:41.314 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-error-handler-group-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = error-handler-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:20:41.315 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:20:41.318 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:20:41.319 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:20:41.319 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763659241318
2025-11-20 19:20:41.328 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-messages-consumer-group-5
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = messages-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:20:41.328 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:20:41.331 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:20:41.331 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:20:41.333 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763659241331
2025-11-20 19:20:41.335 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-messages-consumer-group-6
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = messages-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:20:41.335 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:20:41.338 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:20:41.338 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:20:41.338 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763659241338
2025-11-20 19:20:41.340 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-messages-consumer-group-7
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = messages-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:20:41.340 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:20:41.343 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:20:41.343 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:20:41.343 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763659241343
2025-11-20 19:20:41.344 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-orders-consumer-group-8
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = orders-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:20:41.344 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:20:41.347 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:20:41.348 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:20:41.348 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763659241347
2025-11-20 19:20:41.349 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-orders-consumer-group-9
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = orders-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:20:41.349 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:20:41.351 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:20:41.351 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:20:41.351 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763659241351
2025-11-20 19:20:41.353 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-orders-consumer-group-10
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = orders-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:20:41.354 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:20:41.356 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:20:41.356 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:20:41.356 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763659241356
2025-11-20 19:20:41.358 [main] [] WARN  o.s.k.l.ConcurrentMessageListenerContainer - When specific partitions are provided, the concurrency must be less than or equal to the number of partitions; reduced from 3 to 2
2025-11-20 19:20:41.359 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-partition-specific-group-11
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = partition-specific-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:20:41.359 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:20:41.363 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:20:41.363 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:20:41.363 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763659241363
2025-11-20 19:20:41.367 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-partition-specific-group-12
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = partition-specific-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:20:41.367 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:20:41.370 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:20:41.370 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:20:41.370 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763659241370
2025-11-20 19:20:41.371 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-batch-consumer-group-13
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = batch-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:20:41.372 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:20:41.374 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:20:41.375 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:20:41.375 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763659241374
2025-11-20 19:20:41.376 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group-1-14
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group-1
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:20:41.376 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:20:41.379 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:20:41.379 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:20:41.379 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763659241379
2025-11-20 19:20:41.381 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group-1-15
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group-1
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:20:41.381 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:20:41.383 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:20:41.383 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:20:41.383 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763659241383
2025-11-20 19:20:41.385 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group-1-16
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group-1
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:20:41.386 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:20:41.388 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:20:41.389 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:20:41.389 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763659241388
2025-11-20 19:20:41.390 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group-2-17
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group-2
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:20:41.390 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:20:41.393 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:20:41.394 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:20:41.394 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763659241393
2025-11-20 19:20:41.395 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group-2-18
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group-2
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:20:41.395 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:20:41.398 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:20:41.398 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:20:41.398 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763659241398
2025-11-20 19:20:41.400 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group-2-19
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group-2
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:20:41.400 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:20:41.402 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:20:41.402 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:20:41.402 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763659241402
2025-11-20 19:20:41.408 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-transactional-consumer-group-20
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = transactional-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:20:41.408 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:20:41.411 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:20:41.411 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:20:41.411 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763659241411
2025-11-20 19:20:41.413 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-manual-commit-group-21
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = manual-commit-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:20:41.413 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:20:41.415 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:20:41.415 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:20:41.415 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763659241415
2025-11-20 19:20:41.417 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-detailed-consumer-group-22
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = detailed-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:20:41.417 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:20:41.420 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:20:41.420 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:20:41.420 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763659241420
2025-11-20 19:20:41.421 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-detailed-consumer-group-23
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = detailed-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:20:41.422 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:20:41.425 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:20:41.425 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:20:41.425 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763659241425
2025-11-20 19:20:41.426 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-detailed-consumer-group-24
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = detailed-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:20:41.427 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:20:41.429 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:20:41.429 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:20:41.429 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763659241429
2025-11-20 19:20:41.430 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-test-consumer-group-25
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:20:41.431 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:20:41.433 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:20:41.433 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:20:41.433 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763659241433
2025-11-20 19:20:41.435 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-test-consumer-group-26
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:20:41.435 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:20:41.436 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:20:41.438 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:20:41.438 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763659241436
2025-11-20 19:20:41.438 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-test-consumer-group-27
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:20:41.438 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:20:41.442 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:20:41.442 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:20:41.442 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763659241442
2025-11-20 19:20:41.451 [main] [] INFO  c.v.k.KafkaEnhancedApplication - Started KafkaEnhancedApplication in 2.379 seconds (process running for 2.768)
2025-11-20 19:20:41.639 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dlt-consumer-group-1, groupId=dlt-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:20:41.640 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dlt-consumer-group-2, groupId=dlt-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:20:41.640 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dlt-consumer-group-3, groupId=dlt-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:20:41.645 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-error-handler-group-4, groupId=error-handler-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:20:41.645 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-batch-consumer-group-13, groupId=batch-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:20:41.645 [org.springframework.kafka.KafkaListenerEndpointContainer#9-0-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-orders-consumer-group-8, groupId=orders-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:20:41.645 [org.springframework.kafka.KafkaListenerEndpointContainer#10-1-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-test-consumer-group-26, groupId=test-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:20:41.645 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-group-2-17, groupId=group-2] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:20:41.645 [org.springframework.kafka.KafkaListenerEndpointContainer#8-2-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-messages-consumer-group-7, groupId=messages-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:20:41.645 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-group-1-15, groupId=group-1] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:20:41.645 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-detailed-consumer-group-24, groupId=detailed-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:20:41.645 [org.springframework.kafka.KafkaListenerEndpointContainer#9-1-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-orders-consumer-group-9, groupId=orders-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:20:41.645 [org.springframework.kafka.KafkaListenerEndpointContainer#10-0-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-test-consumer-group-25, groupId=test-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:20:41.645 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-detailed-consumer-group-23, groupId=detailed-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:20:41.645 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-group-2-19, groupId=group-2] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:20:41.645 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-transactional-consumer-group-20, groupId=transactional-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:20:41.646 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-partition-specific-group-11, groupId=partition-specific-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:20:41.645 [org.springframework.kafka.KafkaListenerEndpointContainer#8-0-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-messages-consumer-group-5, groupId=messages-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:20:41.645 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-group-1-14, groupId=group-1] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:20:41.645 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-group-1-16, groupId=group-1] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:20:41.645 [org.springframework.kafka.KafkaListenerEndpointContainer#9-2-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-orders-consumer-group-10, groupId=orders-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:20:41.645 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-manual-commit-group-21, groupId=manual-commit-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:20:41.645 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-group-2-18, groupId=group-2] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:20:41.645 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-detailed-consumer-group-22, groupId=detailed-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:20:41.646 [org.springframework.kafka.KafkaListenerEndpointContainer#8-1-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-messages-consumer-group-6, groupId=messages-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:20:41.646 [org.springframework.kafka.KafkaListenerEndpointContainer#10-2-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-test-consumer-group-27, groupId=test-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:20:41.646 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-partition-specific-group-12, groupId=partition-specific-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:20:41.921 [RMI TCP Connection(3)-192.168.56.1] [] INFO  o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
2025-11-20 19:20:41.921 [RMI TCP Connection(3)-192.168.56.1] [] INFO  o.s.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
2025-11-20 19:20:41.922 [RMI TCP Connection(3)-192.168.56.1] [] INFO  o.s.web.servlet.DispatcherServlet - Completed initialization in 1 ms
2025-11-20 19:20:41.943 [RMI TCP Connection(4)-192.168.56.1] [] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = kafka-enhanced-spring-boot-production-producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = snappy
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 10
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 3
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 1000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2025-11-20 19:20:41.944 [RMI TCP Connection(4)-192.168.56.1] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:20:41.960 [RMI TCP Connection(4)-192.168.56.1] [] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=kafka-enhanced-spring-boot-production-producer-1] Instantiated an idempotent producer.
2025-11-20 19:20:41.970 [RMI TCP Connection(4)-192.168.56.1] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:20:41.971 [RMI TCP Connection(4)-192.168.56.1] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:20:41.971 [RMI TCP Connection(4)-192.168.56.1] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763659241970
2025-11-20 19:20:41.974 [kafka-producer-network-thread | kafka-enhanced-spring-boot-production-producer-1] [] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=kafka-enhanced-spring-boot-production-producer-1] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:20:41.975 [kafka-producer-network-thread | kafka-enhanced-spring-boot-production-producer-1] [] INFO  o.a.k.c.p.i.TransactionManager - [Producer clientId=kafka-enhanced-spring-boot-production-producer-1] ProducerId set to 4 with epoch 0
2025-11-20 19:21:24.502 [http-nio-8080-exec-3] [9b698b21-7ea8-425a-9d6c-a29ce394f257] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = kafka-enhanced-spring-boot-production-producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = tx-producer-10
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2025-11-20 19:21:24.502 [http-nio-8080-exec-3] [9b698b21-7ea8-425a-9d6c-a29ce394f257] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:21:24.503 [http-nio-8080-exec-3] [9b698b21-7ea8-425a-9d6c-a29ce394f257] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=kafka-enhanced-spring-boot-production-producer-1, transactionalId=tx-producer-10] Instantiated a transactional producer.
2025-11-20 19:21:24.510 [http-nio-8080-exec-3] [9b698b21-7ea8-425a-9d6c-a29ce394f257] INFO  o.a.kafka.common.utils.AppInfoParser - The mbean of App info: [kafka.producer], id: [kafka-enhanced-spring-boot-production-producer-1] already exists, so skipping a new mbean creation.
2025-11-20 19:21:24.511 [http-nio-8080-exec-3] [9b698b21-7ea8-425a-9d6c-a29ce394f257] INFO  o.a.k.c.p.i.TransactionManager - [Producer clientId=kafka-enhanced-spring-boot-production-producer-1, transactionalId=tx-producer-10] Invoking InitProducerId for the first time in order to acquire a producer ID
2025-11-20 19:21:24.516 [kafka-producer-network-thread | kafka-enhanced-spring-boot-production-producer-1] [] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=kafka-enhanced-spring-boot-production-producer-1, transactionalId=tx-producer-10] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:21:24.516 [kafka-producer-network-thread | kafka-enhanced-spring-boot-production-producer-1] [] INFO  o.a.k.c.p.i.TransactionManager - [Producer clientId=kafka-enhanced-spring-boot-production-producer-1, transactionalId=tx-producer-10] Discovered transaction coordinator localhost:9092 (id: 1 rack: null)
2025-11-20 19:21:24.636 [kafka-producer-network-thread | kafka-enhanced-spring-boot-production-producer-1] [] INFO  o.a.k.c.p.i.TransactionManager - [Producer clientId=kafka-enhanced-spring-boot-production-producer-1, transactionalId=tx-producer-10] ProducerId set to 1 with epoch 1
2025-11-20 19:21:24.640 [http-nio-8080-exec-3] [9b698b21-7ea8-425a-9d6c-a29ce394f257] INFO  c.v.k.service.TransactionalService - 🔐 Starting transaction for: ac853901-cad6-422e-a8ff-903950008bc6
2025-11-20 19:21:24.684 [http-nio-8080-exec-3] [9b698b21-7ea8-425a-9d6c-a29ce394f257] INFO  c.v.k.service.TransactionalService - ✅ Transaction committed: ac853901-cad6-422e-a8ff-903950008bc6
2025-11-20 19:21:24.684 [http-nio-8080-exec-3] [9b698b21-7ea8-425a-9d6c-a29ce394f257] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages sent counter incremented
2025-11-20 19:21:24.783 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╔════════════════════════════════════════════════════╗
2025-11-20 19:21:24.784 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ║     TRANSACTIONAL CONSUMER (READ_COMMITTED)        ║
2025-11-20 19:21:24.784 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╠════════════════════════════════════════════════════╣
2025-11-20 19:21:24.784 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Transaction ID: ac853901-cad6-422e-a8ff-903950008bc6
2025-11-20 19:21:24.784 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Type: DEBIT
2025-11-20 19:21:24.784 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Account: ACC-123
2025-11-20 19:21:24.784 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Amount: $100.5
2025-11-20 19:21:24.784 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Description: Single transaction
2025-11-20 19:21:24.785 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Partition: 1
2025-11-20 19:21:24.785 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Offset: 0
2025-11-20 19:21:24.785 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╚════════════════════════════════════════════════════╝
2025-11-20 19:21:24.785 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages received counter incremented
2025-11-20 19:25:20.757 [http-nio-8080-exec-5] [b3d9fe00-8e73-4726-ba1b-53ecdc06c3ea] INFO  c.v.k.c.TransactionController - 📤 Sending batch of 3 transactions (ALL SUCCESS)
2025-11-20 19:25:20.758 [http-nio-8080-exec-5] [b3d9fe00-8e73-4726-ba1b-53ecdc06c3ea] INFO  c.v.k.service.TransactionalService - 🔐 Starting BATCH transaction with 3 items
2025-11-20 19:25:20.758 [http-nio-8080-exec-5] [b3d9fe00-8e73-4726-ba1b-53ecdc06c3ea] INFO  c.v.k.service.TransactionalService -   [1/3] Processing: 357a61f3-18b5-4d86-b1a1-26fe785b7d9a - DEBIT
2025-11-20 19:25:20.759 [http-nio-8080-exec-5] [b3d9fe00-8e73-4726-ba1b-53ecdc06c3ea] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages sent counter incremented
2025-11-20 19:25:21.262 [http-nio-8080-exec-5] [b3d9fe00-8e73-4726-ba1b-53ecdc06c3ea] INFO  c.v.k.service.TransactionalService -   [2/3] Processing: df89c8b5-88fd-497a-bca5-b8884f438b82 - CREDIT
2025-11-20 19:25:21.263 [http-nio-8080-exec-5] [b3d9fe00-8e73-4726-ba1b-53ecdc06c3ea] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages sent counter incremented
2025-11-20 19:25:21.775 [http-nio-8080-exec-5] [b3d9fe00-8e73-4726-ba1b-53ecdc06c3ea] INFO  c.v.k.service.TransactionalService -   [3/3] Processing: dc8f5b68-daad-4867-b4d2-b50c3d0e380e - TRANSFER
2025-11-20 19:25:21.775 [http-nio-8080-exec-5] [b3d9fe00-8e73-4726-ba1b-53ecdc06c3ea] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages sent counter incremented
2025-11-20 19:25:22.277 [http-nio-8080-exec-5] [b3d9fe00-8e73-4726-ba1b-53ecdc06c3ea] INFO  c.v.k.service.TransactionalService - ✅ BATCH transaction COMMITTED - All 3 transactions successful
2025-11-20 19:25:22.285 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╔════════════════════════════════════════════════════╗
2025-11-20 19:25:22.286 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ║     TRANSACTIONAL CONSUMER (READ_COMMITTED)        ║
2025-11-20 19:25:22.286 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╠════════════════════════════════════════════════════╣
2025-11-20 19:25:22.286 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Transaction ID: 357a61f3-18b5-4d86-b1a1-26fe785b7d9a
2025-11-20 19:25:22.286 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Type: DEBIT
2025-11-20 19:25:22.286 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Account: ACC-001
2025-11-20 19:25:22.286 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Amount: $100.0
2025-11-20 19:25:22.286 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Description: Payment 1
2025-11-20 19:25:22.286 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Partition: 1
2025-11-20 19:25:22.286 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Offset: 2
2025-11-20 19:25:22.286 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╚════════════════════════════════════════════════════╝
2025-11-20 19:25:22.286 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages received counter incremented
2025-11-20 19:25:22.286 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╔════════════════════════════════════════════════════╗
2025-11-20 19:25:22.286 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ║     TRANSACTIONAL CONSUMER (READ_COMMITTED)        ║
2025-11-20 19:25:22.286 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╠════════════════════════════════════════════════════╣
2025-11-20 19:25:22.286 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Transaction ID: df89c8b5-88fd-497a-bca5-b8884f438b82
2025-11-20 19:25:22.286 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Type: CREDIT
2025-11-20 19:25:22.287 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Account: ACC-002
2025-11-20 19:25:22.287 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Amount: $100.0
2025-11-20 19:25:22.287 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Description: Payment 2
2025-11-20 19:25:22.287 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Partition: 0
2025-11-20 19:25:22.287 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Offset: 2
2025-11-20 19:25:22.287 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╚════════════════════════════════════════════════════╝
2025-11-20 19:25:22.287 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages received counter incremented
2025-11-20 19:25:22.287 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╔════════════════════════════════════════════════════╗
2025-11-20 19:25:22.287 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ║     TRANSACTIONAL CONSUMER (READ_COMMITTED)        ║
2025-11-20 19:25:22.287 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╠════════════════════════════════════════════════════╣
2025-11-20 19:25:22.287 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Transaction ID: dc8f5b68-daad-4867-b4d2-b50c3d0e380e
2025-11-20 19:25:22.287 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Type: TRANSFER
2025-11-20 19:25:22.287 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Account: ACC-003
2025-11-20 19:25:22.287 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Amount: $50.0
2025-11-20 19:25:22.287 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Description: Payment 3
2025-11-20 19:25:22.287 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Partition: 0
2025-11-20 19:25:22.287 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Offset: 3
2025-11-20 19:25:22.287 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╚════════════════════════════════════════════════════╝
2025-11-20 19:25:22.287 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages received counter incremented
2025-11-20 19:27:31.648 [http-nio-8080-exec-8] [179c35d9-ee69-463f-8c30-94ccff90a020] INFO  c.v.k.c.TransactionController - 📤 Sending batch of 3 transactions (WILL FAIL)
2025-11-20 19:27:31.649 [http-nio-8080-exec-8] [179c35d9-ee69-463f-8c30-94ccff90a020] INFO  c.v.k.service.TransactionalService - 🔐 Starting BATCH transaction with 3 items
2025-11-20 19:27:31.649 [http-nio-8080-exec-8] [179c35d9-ee69-463f-8c30-94ccff90a020] INFO  c.v.k.service.TransactionalService -   [1/3] Processing: 0e654f21-c507-4a8f-9337-a56630119837 - DEBIT
2025-11-20 19:27:31.649 [http-nio-8080-exec-8] [179c35d9-ee69-463f-8c30-94ccff90a020] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages sent counter incremented
2025-11-20 19:27:32.153 [http-nio-8080-exec-8] [179c35d9-ee69-463f-8c30-94ccff90a020] INFO  c.v.k.service.TransactionalService -   [2/3] Processing: 712e741e-b279-4952-9640-23b9d1dfd40b - ERROR
2025-11-20 19:27:32.154 [http-nio-8080-exec-8] [179c35d9-ee69-463f-8c30-94ccff90a020] ERROR c.v.k.service.TransactionalService - ❌ BATCH transaction ROLLED BACK - Error: Simulated transaction failure on item 2
2025-11-20 19:27:32.154 [http-nio-8080-exec-8] [179c35d9-ee69-463f-8c30-94ccff90a020] WARN  c.v.k.metrics.KafkaMetricsService - 📊 Messages failed counter incremented
2025-11-20 19:27:32.154 [http-nio-8080-exec-8] [179c35d9-ee69-463f-8c30-94ccff90a020] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=kafka-enhanced-spring-boot-production-producer-1, transactionalId=tx-producer-10] Aborting incomplete transaction
2025-11-20 19:30:09.505 [http-nio-8080-exec-1] [960ee680-9aef-41b3-a600-ace666fdc234] INFO  c.v.k.c.TransactionController - 📤 Sending custom batch of 2 transactions
2025-11-20 19:30:09.505 [http-nio-8080-exec-1] [960ee680-9aef-41b3-a600-ace666fdc234] INFO  c.v.k.service.TransactionalService - 🔐 Starting BATCH transaction with 2 items
2025-11-20 19:30:09.506 [http-nio-8080-exec-1] [960ee680-9aef-41b3-a600-ace666fdc234] INFO  c.v.k.service.TransactionalService -   [1/2] Processing: c28501bb-3a5a-45de-bb12-da3aec66b27c - DEBIT
2025-11-20 19:30:09.506 [http-nio-8080-exec-1] [960ee680-9aef-41b3-a600-ace666fdc234] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages sent counter incremented
2025-11-20 19:30:10.018 [http-nio-8080-exec-1] [960ee680-9aef-41b3-a600-ace666fdc234] INFO  c.v.k.service.TransactionalService -   [2/2] Processing: 5e38e70f-78c8-4f25-bfd1-bb04dbe0bff8 - CREDIT
2025-11-20 19:30:10.019 [http-nio-8080-exec-1] [960ee680-9aef-41b3-a600-ace666fdc234] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages sent counter incremented
2025-11-20 19:30:10.533 [http-nio-8080-exec-1] [960ee680-9aef-41b3-a600-ace666fdc234] INFO  c.v.k.service.TransactionalService - ✅ BATCH transaction COMMITTED - All 2 transactions successful
2025-11-20 19:30:10.541 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╔════════════════════════════════════════════════════╗
2025-11-20 19:30:10.542 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ║     TRANSACTIONAL CONSUMER (READ_COMMITTED)        ║
2025-11-20 19:30:10.542 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╠════════════════════════════════════════════════════╣
2025-11-20 19:30:10.542 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Transaction ID: 5e38e70f-78c8-4f25-bfd1-bb04dbe0bff8
2025-11-20 19:30:10.542 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Type: CREDIT
2025-11-20 19:30:10.542 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Account: ACC-002
2025-11-20 19:30:10.542 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Amount: $75.5
2025-11-20 19:30:10.542 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Description: Refund
2025-11-20 19:30:10.542 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Partition: 1
2025-11-20 19:30:10.542 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Offset: 4
2025-11-20 19:30:10.542 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╚════════════════════════════════════════════════════╝
2025-11-20 19:30:10.542 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages received counter incremented
2025-11-20 19:30:10.542 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╔════════════════════════════════════════════════════╗
2025-11-20 19:30:10.542 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ║     TRANSACTIONAL CONSUMER (READ_COMMITTED)        ║
2025-11-20 19:30:10.542 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╠════════════════════════════════════════════════════╣
2025-11-20 19:30:10.542 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Transaction ID: c28501bb-3a5a-45de-bb12-da3aec66b27c
2025-11-20 19:30:10.542 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Type: DEBIT
2025-11-20 19:30:10.542 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Account: ACC-001
2025-11-20 19:30:10.542 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Amount: $50.0
2025-11-20 19:30:10.543 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Description: Purchase 1
2025-11-20 19:30:10.543 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Partition: 0
2025-11-20 19:30:10.543 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Offset: 7
2025-11-20 19:30:10.543 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╚════════════════════════════════════════════════════╝
2025-11-20 19:30:10.543 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages received counter incremented
2025-11-20 19:31:09.625 [http-nio-8080-exec-2] [2319e213-bef5-4d60-930e-b12255a02a19] INFO  c.v.k.c.TransactionController - 📤 Sending custom batch of 2 transactions
2025-11-20 19:31:09.625 [http-nio-8080-exec-2] [2319e213-bef5-4d60-930e-b12255a02a19] INFO  c.v.k.service.TransactionalService - 🔐 Starting BATCH transaction with 2 items
2025-11-20 19:31:09.625 [http-nio-8080-exec-2] [2319e213-bef5-4d60-930e-b12255a02a19] INFO  c.v.k.service.TransactionalService -   [1/2] Processing: d66f0dfa-1e95-4e58-89ba-9f94dde76fd6 - DEBIT
2025-11-20 19:31:09.626 [http-nio-8080-exec-2] [2319e213-bef5-4d60-930e-b12255a02a19] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages sent counter incremented
2025-11-20 19:31:10.138 [http-nio-8080-exec-2] [2319e213-bef5-4d60-930e-b12255a02a19] INFO  c.v.k.service.TransactionalService -   [2/2] Processing: 27bb6e08-d46a-484b-89c4-39e1e81a0559 - ERROR
2025-11-20 19:31:10.138 [http-nio-8080-exec-2] [2319e213-bef5-4d60-930e-b12255a02a19] ERROR c.v.k.service.TransactionalService - ❌ BATCH transaction ROLLED BACK - Error: Simulated transaction failure on item 2
2025-11-20 19:31:10.138 [http-nio-8080-exec-2] [2319e213-bef5-4d60-930e-b12255a02a19] WARN  c.v.k.metrics.KafkaMetricsService - 📊 Messages failed counter incremented
2025-11-20 19:31:10.138 [http-nio-8080-exec-2] [2319e213-bef5-4d60-930e-b12255a02a19] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=kafka-enhanced-spring-boot-production-producer-1, transactionalId=tx-producer-10] Aborting incomplete transaction
2025-11-20 19:31:35.512 [http-nio-8080-exec-6] [91775349-c5c9-4a3b-bafa-253478c0c5cb] INFO  c.v.k.c.TransactionController - 📤 Sending custom batch of 2 transactions
2025-11-20 19:31:35.513 [http-nio-8080-exec-6] [91775349-c5c9-4a3b-bafa-253478c0c5cb] INFO  c.v.k.service.TransactionalService - 🔐 Starting BATCH transaction with 2 items
2025-11-20 19:31:35.513 [http-nio-8080-exec-6] [91775349-c5c9-4a3b-bafa-253478c0c5cb] INFO  c.v.k.service.TransactionalService -   [1/2] Processing: 25918a47-53b6-4ea2-96fb-3bfd7f1c650d - DEBIT
2025-11-20 19:31:35.513 [http-nio-8080-exec-6] [91775349-c5c9-4a3b-bafa-253478c0c5cb] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages sent counter incremented
2025-11-20 19:31:36.026 [http-nio-8080-exec-6] [91775349-c5c9-4a3b-bafa-253478c0c5cb] INFO  c.v.k.service.TransactionalService -   [2/2] Processing: 745b7060-a2c9-4159-9756-33f9294a180f - ERROR
2025-11-20 19:31:36.026 [http-nio-8080-exec-6] [91775349-c5c9-4a3b-bafa-253478c0c5cb] ERROR c.v.k.service.TransactionalService - ❌ BATCH transaction ROLLED BACK - Error: Simulated transaction failure on item 2
2025-11-20 19:31:36.026 [http-nio-8080-exec-6] [91775349-c5c9-4a3b-bafa-253478c0c5cb] WARN  c.v.k.metrics.KafkaMetricsService - 📊 Messages failed counter incremented
2025-11-20 19:31:36.026 [http-nio-8080-exec-6] [91775349-c5c9-4a3b-bafa-253478c0c5cb] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=kafka-enhanced-spring-boot-production-producer-1, transactionalId=tx-producer-10] Aborting incomplete transaction
2025-11-20 19:33:22.350 [http-nio-8080-exec-8] [1d44f856-d3ee-4695-801a-269cd6e4ede3] INFO  c.v.k.service.TransactionalService - 🔐 Starting transaction for: f99429db-7c5e-4681-9e65-b0c6841959fb
2025-11-20 19:33:22.351 [http-nio-8080-exec-8] [1d44f856-d3ee-4695-801a-269cd6e4ede3] INFO  c.v.k.service.TransactionalService - ✅ Transaction committed: f99429db-7c5e-4681-9e65-b0c6841959fb
2025-11-20 19:33:22.351 [http-nio-8080-exec-8] [1d44f856-d3ee-4695-801a-269cd6e4ede3] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages sent counter incremented
2025-11-20 19:33:22.360 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╔════════════════════════════════════════════════════╗
2025-11-20 19:33:22.361 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ║     TRANSACTIONAL CONSUMER (READ_COMMITTED)        ║
2025-11-20 19:33:22.361 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╠════════════════════════════════════════════════════╣
2025-11-20 19:33:22.361 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Transaction ID: f99429db-7c5e-4681-9e65-b0c6841959fb
2025-11-20 19:33:22.361 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Type: DEBIT
2025-11-20 19:33:22.361 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Account: ACC-123
2025-11-20 19:33:22.361 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Amount: $100.5
2025-11-20 19:33:22.361 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Description: Single transaction
2025-11-20 19:33:22.361 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Partition: 1
2025-11-20 19:33:22.361 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Offset: 8
2025-11-20 19:33:22.361 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╚════════════════════════════════════════════════════╝
2025-11-20 19:33:22.361 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages received counter incremented
2025-11-20 19:35:10.559 [http-nio-8080-exec-1] [45b6a7e7-f77a-40cc-8fd4-92ac1511ad78] INFO  c.v.k.c.TransactionController - 📤 Sending batch of 3 transactions (ALL SUCCESS)
2025-11-20 19:35:10.560 [http-nio-8080-exec-1] [45b6a7e7-f77a-40cc-8fd4-92ac1511ad78] INFO  c.v.k.service.TransactionalService - 🔐 Starting BATCH transaction with 3 items
2025-11-20 19:35:10.560 [http-nio-8080-exec-1] [45b6a7e7-f77a-40cc-8fd4-92ac1511ad78] INFO  c.v.k.service.TransactionalService -   [1/3] Processing: fb4705d0-2a64-46c5-91ea-b68d36c0c6a4 - DEBIT
2025-11-20 19:35:10.561 [http-nio-8080-exec-1] [45b6a7e7-f77a-40cc-8fd4-92ac1511ad78] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages sent counter incremented
2025-11-20 19:35:11.073 [http-nio-8080-exec-1] [45b6a7e7-f77a-40cc-8fd4-92ac1511ad78] INFO  c.v.k.service.TransactionalService -   [2/3] Processing: 1b2e804d-6dc4-4bc8-95b3-378e49df5ce2 - CREDIT
2025-11-20 19:35:11.073 [http-nio-8080-exec-1] [45b6a7e7-f77a-40cc-8fd4-92ac1511ad78] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages sent counter incremented
2025-11-20 19:35:11.577 [http-nio-8080-exec-1] [45b6a7e7-f77a-40cc-8fd4-92ac1511ad78] INFO  c.v.k.service.TransactionalService -   [3/3] Processing: 07bda47a-a197-4fb8-9019-073e9346366e - TRANSFER
2025-11-20 19:35:11.577 [http-nio-8080-exec-1] [45b6a7e7-f77a-40cc-8fd4-92ac1511ad78] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages sent counter incremented
2025-11-20 19:35:12.091 [http-nio-8080-exec-1] [45b6a7e7-f77a-40cc-8fd4-92ac1511ad78] INFO  c.v.k.service.TransactionalService - ✅ BATCH transaction COMMITTED - All 3 transactions successful
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╔════════════════════════════════════════════════════╗
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ║     TRANSACTIONAL CONSUMER (READ_COMMITTED)        ║
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╠════════════════════════════════════════════════════╣
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Transaction ID: fb4705d0-2a64-46c5-91ea-b68d36c0c6a4
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Type: DEBIT
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Account: ACC-001
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Amount: $100.0
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Description: Payment 1
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Partition: 1
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Offset: 10
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╚════════════════════════════════════════════════════╝
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages received counter incremented
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╔════════════════════════════════════════════════════╗
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ║     TRANSACTIONAL CONSUMER (READ_COMMITTED)        ║
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╠════════════════════════════════════════════════════╣
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Transaction ID: 1b2e804d-6dc4-4bc8-95b3-378e49df5ce2
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Type: CREDIT
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Account: ACC-002
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Amount: $100.0
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Description: Payment 2
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Partition: 1
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Offset: 11
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╚════════════════════════════════════════════════════╝
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages received counter incremented
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╔════════════════════════════════════════════════════╗
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ║     TRANSACTIONAL CONSUMER (READ_COMMITTED)        ║
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╠════════════════════════════════════════════════════╣
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Transaction ID: 07bda47a-a197-4fb8-9019-073e9346366e
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Type: TRANSFER
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Account: ACC-003
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Amount: $50.0
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Description: Payment 3
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Partition: 1
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Offset: 12
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╚════════════════════════════════════════════════════╝
2025-11-20 19:35:12.095 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages received counter incremented
2025-11-20 19:37:41.425 [http-nio-8080-exec-4] [1c898377-b721-47cb-9943-55da50e90c33] INFO  c.v.k.c.TransactionController - 📤 Sending batch of 3 transactions (WILL FAIL)
2025-11-20 19:37:41.425 [http-nio-8080-exec-4] [1c898377-b721-47cb-9943-55da50e90c33] INFO  c.v.k.service.TransactionalService - 🔐 Starting BATCH transaction with 3 items
2025-11-20 19:37:41.425 [http-nio-8080-exec-4] [1c898377-b721-47cb-9943-55da50e90c33] INFO  c.v.k.service.TransactionalService -   [1/3] Processing: ed2b9f87-9a56-402d-bab0-e334e97eb287 - DEBIT
2025-11-20 19:37:41.426 [http-nio-8080-exec-4] [1c898377-b721-47cb-9943-55da50e90c33] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages sent counter incremented
2025-11-20 19:37:41.928 [http-nio-8080-exec-4] [1c898377-b721-47cb-9943-55da50e90c33] INFO  c.v.k.service.TransactionalService -   [2/3] Processing: 3e509204-eec5-469e-87f9-4ae70acfd297 - ERROR
2025-11-20 19:37:41.928 [http-nio-8080-exec-4] [1c898377-b721-47cb-9943-55da50e90c33] ERROR c.v.k.service.TransactionalService - ❌ BATCH transaction ROLLED BACK - Error: Simulated transaction failure on item 2
2025-11-20 19:37:41.928 [http-nio-8080-exec-4] [1c898377-b721-47cb-9943-55da50e90c33] WARN  c.v.k.metrics.KafkaMetricsService - 📊 Messages failed counter incremented
2025-11-20 19:37:41.928 [http-nio-8080-exec-4] [1c898377-b721-47cb-9943-55da50e90c33] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=kafka-enhanced-spring-boot-production-producer-1, transactionalId=tx-producer-10] Aborting incomplete transaction
2025-11-20 19:37:51.593 [http-nio-8080-exec-5] [14a86a6c-1864-421b-9706-94a4c94f6680] INFO  c.v.k.c.TransactionController - 📤 Sending batch of 3 transactions (WILL FAIL)
2025-11-20 19:37:51.593 [http-nio-8080-exec-5] [14a86a6c-1864-421b-9706-94a4c94f6680] INFO  c.v.k.service.TransactionalService - 🔐 Starting BATCH transaction with 3 items
2025-11-20 19:37:51.593 [http-nio-8080-exec-5] [14a86a6c-1864-421b-9706-94a4c94f6680] INFO  c.v.k.service.TransactionalService -   [1/3] Processing: 386e5f59-07d1-4ae6-85a1-a59f90df1cd7 - DEBIT
2025-11-20 19:37:51.593 [http-nio-8080-exec-5] [14a86a6c-1864-421b-9706-94a4c94f6680] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages sent counter incremented
2025-11-20 19:37:52.100 [http-nio-8080-exec-5] [14a86a6c-1864-421b-9706-94a4c94f6680] INFO  c.v.k.service.TransactionalService -   [2/3] Processing: f764bd89-8c93-4a7f-ad50-97dafe851e74 - ERROR
2025-11-20 19:37:52.100 [http-nio-8080-exec-5] [14a86a6c-1864-421b-9706-94a4c94f6680] ERROR c.v.k.service.TransactionalService - ❌ BATCH transaction ROLLED BACK - Error: Simulated transaction failure on item 2
2025-11-20 19:37:52.100 [http-nio-8080-exec-5] [14a86a6c-1864-421b-9706-94a4c94f6680] WARN  c.v.k.metrics.KafkaMetricsService - 📊 Messages failed counter incremented
2025-11-20 19:37:52.100 [http-nio-8080-exec-5] [14a86a6c-1864-421b-9706-94a4c94f6680] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=kafka-enhanced-spring-boot-production-producer-1, transactionalId=tx-producer-10] Aborting incomplete transaction
2025-11-20 19:38:43.312 [http-nio-8080-exec-6] [3901754b-a3f6-499a-bfcd-32345dd84b13] INFO  c.v.k.c.TransactionController - 📤 Sending custom batch of 2 transactions
2025-11-20 19:38:43.312 [http-nio-8080-exec-6] [3901754b-a3f6-499a-bfcd-32345dd84b13] INFO  c.v.k.service.TransactionalService - 🔐 Starting BATCH transaction with 2 items
2025-11-20 19:38:43.312 [http-nio-8080-exec-6] [3901754b-a3f6-499a-bfcd-32345dd84b13] INFO  c.v.k.service.TransactionalService -   [1/2] Processing: 62426b1f-3994-4521-9678-a9e4f33480e2 - DEBIT
2025-11-20 19:38:43.312 [http-nio-8080-exec-6] [3901754b-a3f6-499a-bfcd-32345dd84b13] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages sent counter incremented
2025-11-20 19:38:43.825 [http-nio-8080-exec-6] [3901754b-a3f6-499a-bfcd-32345dd84b13] INFO  c.v.k.service.TransactionalService -   [2/2] Processing: 56dcdf06-4733-49d3-8d31-e2277a4246ed - CREDIT
2025-11-20 19:38:43.826 [http-nio-8080-exec-6] [3901754b-a3f6-499a-bfcd-32345dd84b13] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages sent counter incremented
2025-11-20 19:38:44.340 [http-nio-8080-exec-6] [3901754b-a3f6-499a-bfcd-32345dd84b13] INFO  c.v.k.service.TransactionalService - ✅ BATCH transaction COMMITTED - All 2 transactions successful
2025-11-20 19:38:44.344 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╔════════════════════════════════════════════════════╗
2025-11-20 19:38:44.344 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ║     TRANSACTIONAL CONSUMER (READ_COMMITTED)        ║
2025-11-20 19:38:44.344 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╠════════════════════════════════════════════════════╣
2025-11-20 19:38:44.344 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Transaction ID: 62426b1f-3994-4521-9678-a9e4f33480e2
2025-11-20 19:38:44.344 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Type: DEBIT
2025-11-20 19:38:44.344 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Account: ACC-001
2025-11-20 19:38:44.344 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Amount: $50.0
2025-11-20 19:38:44.344 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Description: Purchase 1
2025-11-20 19:38:44.344 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Partition: 1
2025-11-20 19:38:44.344 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Offset: 16
2025-11-20 19:38:44.344 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╚════════════════════════════════════════════════════╝
2025-11-20 19:38:44.344 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages received counter incremented
2025-11-20 19:38:44.344 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╔════════════════════════════════════════════════════╗
2025-11-20 19:38:44.344 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ║     TRANSACTIONAL CONSUMER (READ_COMMITTED)        ║
2025-11-20 19:38:44.344 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╠════════════════════════════════════════════════════╣
2025-11-20 19:38:44.344 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Transaction ID: 56dcdf06-4733-49d3-8d31-e2277a4246ed
2025-11-20 19:38:44.344 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Type: CREDIT
2025-11-20 19:38:44.344 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Account: ACC-002
2025-11-20 19:38:44.344 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Amount: $75.5
2025-11-20 19:38:44.344 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Description: Refund
2025-11-20 19:38:44.344 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Partition: 1
2025-11-20 19:38:44.344 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Offset: 17
2025-11-20 19:38:44.344 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╚════════════════════════════════════════════════════╝
2025-11-20 19:38:44.344 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages received counter incremented
2025-11-20 19:38:56.847 [http-nio-8080-exec-7] [66a62a89-aec1-4d7b-a59e-9b560f6a93b4] INFO  c.v.k.c.TransactionController - 📤 Sending custom batch of 2 transactions
2025-11-20 19:38:56.847 [http-nio-8080-exec-7] [66a62a89-aec1-4d7b-a59e-9b560f6a93b4] INFO  c.v.k.service.TransactionalService - 🔐 Starting BATCH transaction with 2 items
2025-11-20 19:38:56.847 [http-nio-8080-exec-7] [66a62a89-aec1-4d7b-a59e-9b560f6a93b4] INFO  c.v.k.service.TransactionalService -   [1/2] Processing: 85311fa1-b2f3-4c1c-8ad4-847bcb05cc1a - DEBIT
2025-11-20 19:38:56.847 [http-nio-8080-exec-7] [66a62a89-aec1-4d7b-a59e-9b560f6a93b4] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages sent counter incremented
2025-11-20 19:38:57.362 [http-nio-8080-exec-7] [66a62a89-aec1-4d7b-a59e-9b560f6a93b4] INFO  c.v.k.service.TransactionalService -   [2/2] Processing: 6ca33f90-40fd-49d5-a4b3-141e38786da7 - CREDIT
2025-11-20 19:38:57.362 [http-nio-8080-exec-7] [66a62a89-aec1-4d7b-a59e-9b560f6a93b4] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages sent counter incremented
2025-11-20 19:38:57.863 [http-nio-8080-exec-7] [66a62a89-aec1-4d7b-a59e-9b560f6a93b4] INFO  c.v.k.service.TransactionalService - ✅ BATCH transaction COMMITTED - All 2 transactions successful
2025-11-20 19:38:57.870 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╔════════════════════════════════════════════════════╗
2025-11-20 19:38:57.870 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ║     TRANSACTIONAL CONSUMER (READ_COMMITTED)        ║
2025-11-20 19:38:57.870 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╠════════════════════════════════════════════════════╣
2025-11-20 19:38:57.870 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Transaction ID: 85311fa1-b2f3-4c1c-8ad4-847bcb05cc1a
2025-11-20 19:38:57.870 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Type: DEBIT
2025-11-20 19:38:57.870 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Account: ACC-001
2025-11-20 19:38:57.870 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Amount: $50.0
2025-11-20 19:38:57.871 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Description: Purchase 1
2025-11-20 19:38:57.871 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Partition: 1
2025-11-20 19:38:57.871 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Offset: 19
2025-11-20 19:38:57.871 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╚════════════════════════════════════════════════════╝
2025-11-20 19:38:57.871 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages received counter incremented
2025-11-20 19:38:57.871 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╔════════════════════════════════════════════════════╗
2025-11-20 19:38:57.871 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ║     TRANSACTIONAL CONSUMER (READ_COMMITTED)        ║
2025-11-20 19:38:57.871 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╠════════════════════════════════════════════════════╣
2025-11-20 19:38:57.871 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Transaction ID: 6ca33f90-40fd-49d5-a4b3-141e38786da7
2025-11-20 19:38:57.871 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Type: CREDIT
2025-11-20 19:38:57.871 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Account: ACC-002
2025-11-20 19:38:57.871 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Amount: $75.5
2025-11-20 19:38:57.871 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Description: Refund
2025-11-20 19:38:57.871 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Partition: 1
2025-11-20 19:38:57.871 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer -   Offset: 20
2025-11-20 19:38:57.871 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  c.v.k.consumer.TransactionalConsumer - ╚════════════════════════════════════════════════════╝
2025-11-20 19:38:57.871 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages received counter incremented
2025-11-20 19:40:12.822 [http-nio-8080-exec-10] [0b0dae73-6fe6-45a4-9903-e69d4f2cc7fb] INFO  c.v.k.c.TransactionController - 📤 Sending custom batch of 2 transactions
2025-11-20 19:40:12.822 [http-nio-8080-exec-10] [0b0dae73-6fe6-45a4-9903-e69d4f2cc7fb] INFO  c.v.k.service.TransactionalService - 🔐 Starting BATCH transaction with 2 items
2025-11-20 19:40:12.822 [http-nio-8080-exec-10] [0b0dae73-6fe6-45a4-9903-e69d4f2cc7fb] INFO  c.v.k.service.TransactionalService -   [1/2] Processing: 353bed41-dfc6-4744-8fa4-2af0562954b0 - DEBIT
2025-11-20 19:40:12.823 [http-nio-8080-exec-10] [0b0dae73-6fe6-45a4-9903-e69d4f2cc7fb] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages sent counter incremented
2025-11-20 19:40:13.338 [http-nio-8080-exec-10] [0b0dae73-6fe6-45a4-9903-e69d4f2cc7fb] INFO  c.v.k.service.TransactionalService -   [2/2] Processing: 7120dbcd-ba92-4654-b073-b3b72933d545 - ERROR
2025-11-20 19:40:13.338 [http-nio-8080-exec-10] [0b0dae73-6fe6-45a4-9903-e69d4f2cc7fb] ERROR c.v.k.service.TransactionalService - ❌ BATCH transaction ROLLED BACK - Error: Simulated transaction failure on item 2
2025-11-20 19:40:13.338 [http-nio-8080-exec-10] [0b0dae73-6fe6-45a4-9903-e69d4f2cc7fb] WARN  c.v.k.metrics.KafkaMetricsService - 📊 Messages failed counter incremented
2025-11-20 19:40:13.338 [http-nio-8080-exec-10] [0b0dae73-6fe6-45a4-9903-e69d4f2cc7fb] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=kafka-enhanced-spring-boot-production-producer-1, transactionalId=tx-producer-10] Aborting incomplete transaction
2025-11-20 19:40:20.579 [http-nio-8080-exec-1] [2ebaab15-4751-461d-97cc-d7440036f75d] INFO  c.v.k.c.TransactionController - 📤 Sending custom batch of 2 transactions
2025-11-20 19:40:20.579 [http-nio-8080-exec-1] [2ebaab15-4751-461d-97cc-d7440036f75d] INFO  c.v.k.service.TransactionalService - 🔐 Starting BATCH transaction with 2 items
2025-11-20 19:40:20.579 [http-nio-8080-exec-1] [2ebaab15-4751-461d-97cc-d7440036f75d] INFO  c.v.k.service.TransactionalService -   [1/2] Processing: 8ee6e95f-0ac7-4c92-b8dc-8c6b47f124fe - DEBIT
2025-11-20 19:40:20.579 [http-nio-8080-exec-1] [2ebaab15-4751-461d-97cc-d7440036f75d] DEBUG c.v.k.metrics.KafkaMetricsService - 📊 Messages sent counter incremented
2025-11-20 19:40:21.080 [http-nio-8080-exec-1] [2ebaab15-4751-461d-97cc-d7440036f75d] INFO  c.v.k.service.TransactionalService -   [2/2] Processing: d1cba259-9bf2-4064-b8bd-5ceaba545bb5 - ERROR
2025-11-20 19:40:21.080 [http-nio-8080-exec-1] [2ebaab15-4751-461d-97cc-d7440036f75d] ERROR c.v.k.service.TransactionalService - ❌ BATCH transaction ROLLED BACK - Error: Simulated transaction failure on item 2
2025-11-20 19:40:21.080 [http-nio-8080-exec-1] [2ebaab15-4751-461d-97cc-d7440036f75d] WARN  c.v.k.metrics.KafkaMetricsService - 📊 Messages failed counter incremented
2025-11-20 19:40:21.080 [http-nio-8080-exec-1] [2ebaab15-4751-461d-97cc-d7440036f75d] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=kafka-enhanced-spring-boot-production-producer-1, transactionalId=tx-producer-10] Aborting incomplete transaction
2025-11-20 19:50:30.991 [org.springframework.kafka.KafkaListenerEndpointContainer#10-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:30.991 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:30.991 [org.springframework.kafka.KafkaListenerEndpointContainer#10-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:30.991 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:30.991 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:30.991 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:30.991 [org.springframework.kafka.KafkaListenerEndpointContainer#10-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:30.991 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:30.991 [org.springframework.kafka.KafkaListenerEndpointContainer#10-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:30.991 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:30.991 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:30.991 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:30.995 [org.springframework.kafka.KafkaListenerEndpointContainer#9-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:30.995 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:30.995 [org.springframework.kafka.KafkaListenerEndpointContainer#9-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:30.995 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:30.995 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:30.995 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:30.995 [org.springframework.kafka.KafkaListenerEndpointContainer#10-2-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-test-consumer-group-27 unregistered
2025-11-20 19:50:30.995 [org.springframework.kafka.KafkaListenerEndpointContainer#9-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:30.995 [org.springframework.kafka.KafkaListenerEndpointContainer#9-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:30.996 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dlt-consumer-group-2 unregistered
2025-11-20 19:50:30.996 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:30.996 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:30.996 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:30.996 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:30.998 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dlt-consumer-group-1 unregistered
2025-11-20 19:50:31.000 [org.springframework.kafka.KafkaListenerEndpointContainer#9-0-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-orders-consumer-group-8 unregistered
2025-11-20 19:50:31.000 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dlt-consumer-group-3 unregistered
2025-11-20 19:50:31.000 [org.springframework.kafka.KafkaListenerEndpointContainer#4-1-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-group-1-15 unregistered
2025-11-20 19:50:31.151 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:31.151 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:31.151 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:31.151 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:31.154 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-partition-specific-group-12 unregistered
2025-11-20 19:50:31.322 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:31.322 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:31.322 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:31.322 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:31.322 [org.springframework.kafka.KafkaListenerEndpointContainer#10-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:31.322 [org.springframework.kafka.KafkaListenerEndpointContainer#10-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:31.322 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:31.322 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:31.322 [org.springframework.kafka.KafkaListenerEndpointContainer#8-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:31.322 [org.springframework.kafka.KafkaListenerEndpointContainer#10-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:31.322 [org.springframework.kafka.KafkaListenerEndpointContainer#8-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:31.322 [org.springframework.kafka.KafkaListenerEndpointContainer#10-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:31.322 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:31.322 [org.springframework.kafka.KafkaListenerEndpointContainer#8-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:31.322 [org.springframework.kafka.KafkaListenerEndpointContainer#8-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:31.322 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:31.322 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:31.322 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:31.322 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:31.322 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:31.327 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-transactional-consumer-group-20 unregistered
2025-11-20 19:50:31.328 [org.springframework.kafka.KafkaListenerEndpointContainer#10-1-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-test-consumer-group-26 unregistered
2025-11-20 19:50:31.329 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-group-2-18 unregistered
2025-11-20 19:50:31.329 [org.springframework.kafka.KafkaListenerEndpointContainer#8-2-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-messages-consumer-group-7 unregistered
2025-11-20 19:50:31.329 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-partition-specific-group-11 unregistered
2025-11-20 19:50:31.383 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:31.383 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:31.383 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:31.383 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:31.385 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:31.385 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:31.385 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:31.385 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:31.385 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:31.385 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:31.385 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:31.385 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:31.385 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:31.385 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:31.385 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:31.385 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:31.386 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:31.386 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:31.386 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:31.386 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:31.388 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-group-2-17 unregistered
2025-11-20 19:50:31.388 [org.springframework.kafka.KafkaListenerEndpointContainer#1-2-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-detailed-consumer-group-24 unregistered
2025-11-20 19:50:31.389 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-detailed-consumer-group-22 unregistered
2025-11-20 19:50:31.389 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-group-1-14 unregistered
2025-11-20 19:50:31.390 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-error-handler-group-4 unregistered
2025-11-20 19:50:31.464 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:31.464 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:31.464 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:31.464 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:31.467 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-batch-consumer-group-13 unregistered
2025-11-20 19:50:31.481 [org.springframework.kafka.KafkaListenerEndpointContainer#8-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:31.481 [org.springframework.kafka.KafkaListenerEndpointContainer#8-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:31.482 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:31.482 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:31.482 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:31.482 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:31.482 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:31.482 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:31.482 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:31.482 [org.springframework.kafka.KafkaListenerEndpointContainer#8-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:31.484 [org.springframework.kafka.KafkaListenerEndpointContainer#8-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:31.482 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:31.484 [org.springframework.kafka.KafkaListenerEndpointContainer#9-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:31.484 [org.springframework.kafka.KafkaListenerEndpointContainer#10-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:31.484 [org.springframework.kafka.KafkaListenerEndpointContainer#9-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:31.484 [org.springframework.kafka.KafkaListenerEndpointContainer#10-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:31.484 [org.springframework.kafka.KafkaListenerEndpointContainer#9-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:31.484 [org.springframework.kafka.KafkaListenerEndpointContainer#10-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:31.484 [org.springframework.kafka.KafkaListenerEndpointContainer#9-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:31.484 [org.springframework.kafka.KafkaListenerEndpointContainer#10-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:31.484 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:31.484 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:31.485 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:31.485 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:31.485 [org.springframework.kafka.KafkaListenerEndpointContainer#9-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:31.485 [org.springframework.kafka.KafkaListenerEndpointContainer#9-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:31.485 [org.springframework.kafka.KafkaListenerEndpointContainer#9-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:31.485 [org.springframework.kafka.KafkaListenerEndpointContainer#9-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:31.486 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:31.486 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:31.486 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:31.486 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:31.486 [org.springframework.kafka.KafkaListenerEndpointContainer#8-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:31.486 [org.springframework.kafka.KafkaListenerEndpointContainer#8-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:31.489 [org.springframework.kafka.KafkaListenerEndpointContainer#8-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:31.489 [org.springframework.kafka.KafkaListenerEndpointContainer#8-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:31.494 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-manual-commit-group-21 unregistered
2025-11-20 19:50:31.494 [org.springframework.kafka.KafkaListenerEndpointContainer#9-2-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-orders-consumer-group-10 unregistered
2025-11-20 19:50:31.495 [org.springframework.kafka.KafkaListenerEndpointContainer#8-0-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-messages-consumer-group-5 unregistered
2025-11-20 19:50:31.496 [org.springframework.kafka.KafkaListenerEndpointContainer#1-1-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-detailed-consumer-group-23 unregistered
2025-11-20 19:50:31.496 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-group-2-19 unregistered
2025-11-20 19:50:31.496 [org.springframework.kafka.KafkaListenerEndpointContainer#10-0-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-test-consumer-group-25 unregistered
2025-11-20 19:50:31.497 [org.springframework.kafka.KafkaListenerEndpointContainer#9-1-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-orders-consumer-group-9 unregistered
2025-11-20 19:50:31.497 [org.springframework.kafka.KafkaListenerEndpointContainer#4-2-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-group-1-16 unregistered
2025-11-20 19:50:31.497 [org.springframework.kafka.KafkaListenerEndpointContainer#8-1-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-messages-consumer-group-6 unregistered
2025-11-20 19:50:31.498 [SpringApplicationShutdownHook] [] INFO  o.s.b.w.e.tomcat.GracefulShutdown - Commencing graceful shutdown. Waiting for active requests to complete
2025-11-20 19:50:31.656 [tomcat-shutdown] [] INFO  o.s.b.w.e.tomcat.GracefulShutdown - Graceful shutdown complete
2025-11-20 19:50:31.658 [SpringApplicationShutdownHook] [] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=kafka-enhanced-spring-boot-production-producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2025-11-20 19:50:31.660 [SpringApplicationShutdownHook] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:31.660 [SpringApplicationShutdownHook] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:31.660 [SpringApplicationShutdownHook] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:31.660 [SpringApplicationShutdownHook] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:31.660 [SpringApplicationShutdownHook] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.producer for kafka-enhanced-spring-boot-production-producer-1 unregistered
2025-11-20 19:50:31.660 [SpringApplicationShutdownHook] [] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=kafka-enhanced-spring-boot-production-producer-1, transactionalId=tx-producer-10] Closing the Kafka producer with timeoutMillis = 30000 ms.
2025-11-20 19:50:31.662 [SpringApplicationShutdownHook] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:50:31.662 [SpringApplicationShutdownHook] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:50:31.662 [SpringApplicationShutdownHook] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:50:31.662 [SpringApplicationShutdownHook] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:50:31.662 [SpringApplicationShutdownHook] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.producer for kafka-enhanced-spring-boot-production-producer-1 unregistered
2025-11-20 19:51:33.110 [background-preinit] [] INFO  o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.3.Final
2025-11-20 19:51:33.160 [main] [] INFO  c.v.k.KafkaEnhancedApplicationTests - Starting KafkaEnhancedApplicationTests using Java 17.0.8 with PID 1308 (started by admin in C:\Users\admin\Desktop\COMPLETE\kafka-enhanced-spring-boot-production)
2025-11-20 19:51:33.161 [main] [] DEBUG c.v.k.KafkaEnhancedApplicationTests - Running with Spring Boot v3.5.7, Spring v6.2.12
2025-11-20 19:51:33.162 [main] [] INFO  c.v.k.KafkaEnhancedApplicationTests - No active profile set, falling back to 1 default profile: "default"
2025-11-20 19:51:35.154 [main] [] INFO  c.v.k.config.KafkaErrorHandlerConfig - ? Error Handler configured: 3 retries, 2s backoff, DLT enabled
2025-11-20 19:51:35.221 [main] [] INFO  c.v.k.metrics.KafkaMetricsService - ? Kafka metrics initialized
2025-11-20 19:51:36.891 [main] [] INFO  o.s.b.a.e.web.EndpointLinksResolver - Exposing 4 endpoints beneath base path '/actuator'
2025-11-20 19:51:37.173 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dlt-consumer-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dlt-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:51:37.234 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:51:37.345 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:51:37.345 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:51:37.345 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763661097344
2025-11-20 19:51:37.353 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dlt-consumer-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dlt-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:51:37.353 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:51:37.361 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:51:37.361 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:51:37.361 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763661097360
2025-11-20 19:51:37.364 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-dlt-consumer-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dlt-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:51:37.364 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:51:37.370 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:51:37.370 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:51:37.370 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763661097370
2025-11-20 19:51:37.374 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-error-handler-group-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = error-handler-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:51:37.375 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:51:37.381 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:51:37.381 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:51:37.381 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763661097381
2025-11-20 19:51:37.409 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-messages-consumer-group-5
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = messages-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:51:37.410 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:51:37.423 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:51:37.425 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:51:37.425 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763661097423
2025-11-20 19:51:37.433 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-messages-consumer-group-6
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = messages-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:51:37.435 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:51:37.451 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:51:37.452 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:51:37.452 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763661097451
2025-11-20 19:51:37.458 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-messages-consumer-group-7
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = messages-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:51:37.459 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:51:37.465 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:51:37.466 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:51:37.466 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763661097465
2025-11-20 19:51:37.470 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-orders-consumer-group-8
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = orders-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:51:37.472 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:51:37.479 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:51:37.480 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:51:37.480 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763661097479
2025-11-20 19:51:37.483 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-orders-consumer-group-9
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = orders-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:51:37.484 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:51:37.490 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:51:37.491 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:51:37.491 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763661097490
2025-11-20 19:51:37.493 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-orders-consumer-group-10
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = orders-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:51:37.495 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:51:37.502 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:51:37.503 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:51:37.503 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763661097502
2025-11-20 19:51:37.507 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-detailed-consumer-group-11
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = detailed-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:51:37.508 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:51:37.517 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:51:37.517 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:51:37.517 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763661097517
2025-11-20 19:51:37.520 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-detailed-consumer-group-12
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = detailed-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:51:37.521 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:51:37.524 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:51:37.524 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:51:37.524 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763661097524
2025-11-20 19:51:37.527 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-detailed-consumer-group-13
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = detailed-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:51:37.527 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:51:37.536 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:51:37.537 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:51:37.537 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763661097536
2025-11-20 19:51:37.540 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group-2-14
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group-2
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:51:37.541 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:51:37.549 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:51:37.549 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:51:37.549 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763661097549
2025-11-20 19:51:37.555 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group-2-15
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group-2
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:51:37.556 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:51:37.564 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:51:37.565 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:51:37.565 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763661097564
2025-11-20 19:51:37.568 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group-2-16
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group-2
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:51:37.569 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:51:37.577 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:51:37.578 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:51:37.578 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763661097577
2025-11-20 19:51:37.581 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-batch-consumer-group-17
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = batch-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:51:37.582 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:51:37.589 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:51:37.589 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:51:37.591 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763661097589
2025-11-20 19:51:37.594 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group-1-18
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group-1
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:51:37.595 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:51:37.601 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:51:37.601 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:51:37.601 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763661097601
2025-11-20 19:51:37.604 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group-1-19
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group-1
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:51:37.605 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:51:37.611 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:51:37.612 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:51:37.612 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763661097611
2025-11-20 19:51:37.615 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group-1-20
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group-1
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:51:37.616 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:51:37.621 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:51:37.621 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:51:37.621 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763661097621
2025-11-20 19:51:37.625 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-transactional-consumer-group-21
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = transactional-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:51:37.626 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:51:37.632 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:51:37.633 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:51:37.633 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763661097632
2025-11-20 19:51:37.637 [main] [] WARN  o.s.k.l.ConcurrentMessageListenerContainer - When specific partitions are provided, the concurrency must be less than or equal to the number of partitions; reduced from 3 to 2
2025-11-20 19:51:37.638 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-partition-specific-group-22
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = partition-specific-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:51:37.639 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:51:37.647 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:51:37.647 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:51:37.647 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763661097646
2025-11-20 19:51:37.671 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-partition-specific-group-23
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = partition-specific-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:51:37.672 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:51:37.679 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:51:37.680 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:51:37.680 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763661097679
2025-11-20 19:51:37.684 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-manual-commit-group-24
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = manual-commit-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:51:37.685 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:51:37.692 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:51:37.693 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:51:37.693 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763661097692
2025-11-20 19:51:37.697 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-test-consumer-group-25
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:51:37.698 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:51:37.730 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:51:37.730 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:51:37.730 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763661097730
2025-11-20 19:51:37.734 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-test-consumer-group-26
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:51:37.735 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:51:37.741 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:51:37.741 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:51:37.742 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763661097741
2025-11-20 19:51:37.745 [main] [] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-test-consumer-group-27
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 10000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2025-11-20 19:51:37.745 [main] [] INFO  o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-11-20 19:51:37.752 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-11-20 19:51:37.753 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-11-20 19:51:37.754 [main] [] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1763661097752
2025-11-20 19:51:37.791 [main] [] INFO  c.v.k.KafkaEnhancedApplicationTests - Started KafkaEnhancedApplicationTests in 5.056 seconds (process running for 6.173)
2025-11-20 19:51:38.914 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dlt-consumer-group-2, groupId=dlt-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:51:38.916 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dlt-consumer-group-1, groupId=dlt-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:51:38.914 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-dlt-consumer-group-3, groupId=dlt-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:51:38.921 [org.springframework.kafka.KafkaListenerEndpointContainer#8-1-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-messages-consumer-group-6, groupId=messages-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:51:38.921 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-group-1-18, groupId=group-1] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:51:38.921 [org.springframework.kafka.KafkaListenerEndpointContainer#10-1-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-test-consumer-group-26, groupId=test-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:51:38.921 [org.springframework.kafka.KafkaListenerEndpointContainer#9-0-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-orders-consumer-group-8, groupId=orders-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:51:38.921 [org.springframework.kafka.KafkaListenerEndpointContainer#9-1-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-orders-consumer-group-9, groupId=orders-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:51:38.921 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-partition-specific-group-23, groupId=partition-specific-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:51:38.921 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-group-2-16, groupId=group-2] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:51:38.921 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-batch-consumer-group-17, groupId=batch-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:51:38.921 [org.springframework.kafka.KafkaListenerEndpointContainer#10-0-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-test-consumer-group-25, groupId=test-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:51:38.921 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-group-2-14, groupId=group-2] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:51:38.921 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-error-handler-group-4, groupId=error-handler-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:51:38.921 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-group-2-15, groupId=group-2] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:51:38.921 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-manual-commit-group-24, groupId=manual-commit-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:51:38.921 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-transactional-consumer-group-21, groupId=transactional-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:51:38.921 [org.springframework.kafka.KafkaListenerEndpointContainer#9-2-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-orders-consumer-group-10, groupId=orders-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:51:38.921 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-group-1-20, groupId=group-1] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:51:38.921 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-detailed-consumer-group-13, groupId=detailed-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:51:38.921 [org.springframework.kafka.KafkaListenerEndpointContainer#8-2-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-messages-consumer-group-7, groupId=messages-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:51:38.921 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-group-1-19, groupId=group-1] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:51:38.921 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-detailed-consumer-group-12, groupId=detailed-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:51:38.921 [org.springframework.kafka.KafkaListenerEndpointContainer#8-0-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-messages-consumer-group-5, groupId=messages-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:51:38.921 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-detailed-consumer-group-11, groupId=detailed-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:51:38.921 [org.springframework.kafka.KafkaListenerEndpointContainer#10-2-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-test-consumer-group-27, groupId=test-consumer-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:51:38.921 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [] INFO  org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-partition-specific-group-22, groupId=partition-specific-group] Cluster ID: dFRvbxLsQbW72eKsU34wrw
2025-11-20 19:51:39.508 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] [] INFO  o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-partition-specific-group-23, groupId=partition-specific-group] Node 1 sent an invalid full fetch response with extraIds=(MG1YEF6XTu-Q8kGHPIZWbg), response=()
2025-11-20 19:51:39.508 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [] INFO  o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-partition-specific-group-22, groupId=partition-specific-group] Node 1 sent an invalid full fetch response with extraIds=(MG1YEF6XTu-Q8kGHPIZWbg), response=()
2025-11-20 19:51:39.510 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:51:39.510 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:51:39.510 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:51:39.510 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:51:39.510 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:51:39.511 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:51:39.511 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:51:39.511 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:51:39.524 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-partition-specific-group-23 unregistered
2025-11-20 19:51:39.524 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-partition-specific-group-22 unregistered
2025-11-20 19:51:42.006 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:51:42.007 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:51:42.007 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:51:42.007 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:51:42.009 [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-error-handler-group-4 unregistered
2025-11-20 19:51:42.038 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:51:42.039 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:51:42.039 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:51:42.039 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:51:42.039 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:51:42.039 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:51:42.039 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:51:42.039 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:51:42.039 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:51:42.039 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:51:42.039 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:51:42.039 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:51:42.053 [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-batch-consumer-group-17 unregistered
2025-11-20 19:51:42.054 [org.springframework.kafka.KafkaListenerEndpointContainer#11-0-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-transactional-consumer-group-21 unregistered
2025-11-20 19:51:42.054 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-manual-commit-group-24 unregistered
2025-11-20 19:51:45.022 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:51:45.022 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:51:45.022 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:51:45.022 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:51:45.022 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:51:45.022 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:51:45.023 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:51:45.023 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:51:45.030 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-group-2-14 unregistered
2025-11-20 19:51:45.031 [org.springframework.kafka.KafkaListenerEndpointContainer#3-2-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-group-2-16 unregistered
2025-11-20 19:51:45.036 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:51:45.037 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:51:45.037 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:51:45.037 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:51:45.043 [org.springframework.kafka.KafkaListenerEndpointContainer#8-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:51:45.043 [org.springframework.kafka.KafkaListenerEndpointContainer#8-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:51:45.044 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:51:45.044 [org.springframework.kafka.KafkaListenerEndpointContainer#8-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:51:45.044 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:51:45.044 [org.springframework.kafka.KafkaListenerEndpointContainer#9-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:51:45.044 [org.springframework.kafka.KafkaListenerEndpointContainer#8-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:51:45.044 [org.springframework.kafka.KafkaListenerEndpointContainer#9-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:51:45.044 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:51:45.044 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:51:45.044 [org.springframework.kafka.KafkaListenerEndpointContainer#9-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:51:45.044 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:51:45.044 [org.springframework.kafka.KafkaListenerEndpointContainer#9-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:51:45.044 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:51:45.044 [org.springframework.kafka.KafkaListenerEndpointContainer#10-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:51:45.044 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:51:45.044 [org.springframework.kafka.KafkaListenerEndpointContainer#10-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:51:45.044 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:51:45.044 [org.springframework.kafka.KafkaListenerEndpointContainer#10-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:51:45.044 [org.springframework.kafka.KafkaListenerEndpointContainer#10-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:51:45.044 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:51:45.045 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:51:45.045 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:51:45.045 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:51:45.045 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:51:45.045 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:51:45.045 [org.springframework.kafka.KafkaListenerEndpointContainer#10-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:51:45.045 [org.springframework.kafka.KafkaListenerEndpointContainer#9-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:51:45.045 [org.springframework.kafka.KafkaListenerEndpointContainer#10-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:51:45.045 [org.springframework.kafka.KafkaListenerEndpointContainer#9-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:51:45.046 [org.springframework.kafka.KafkaListenerEndpointContainer#8-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:51:45.046 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:51:45.046 [org.springframework.kafka.KafkaListenerEndpointContainer#8-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:51:45.046 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:51:45.046 [org.springframework.kafka.KafkaListenerEndpointContainer#9-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:51:45.046 [org.springframework.kafka.KafkaListenerEndpointContainer#9-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:51:45.047 [org.springframework.kafka.KafkaListenerEndpointContainer#8-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:51:45.048 [org.springframework.kafka.KafkaListenerEndpointContainer#10-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:51:45.048 [org.springframework.kafka.KafkaListenerEndpointContainer#8-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:51:45.048 [org.springframework.kafka.KafkaListenerEndpointContainer#10-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:51:45.049 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:51:45.050 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:51:45.052 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:51:45.052 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:51:45.053 [org.springframework.kafka.KafkaListenerEndpointContainer#10-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:51:45.053 [org.springframework.kafka.KafkaListenerEndpointContainer#10-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:51:45.053 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:51:45.053 [org.springframework.kafka.KafkaListenerEndpointContainer#9-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:51:45.053 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:51:45.053 [org.springframework.kafka.KafkaListenerEndpointContainer#9-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:51:45.053 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:51:45.053 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:51:45.053 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:51:45.053 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:51:45.055 [org.springframework.kafka.KafkaListenerEndpointContainer#9-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:51:45.055 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:51:45.055 [org.springframework.kafka.KafkaListenerEndpointContainer#9-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:51:45.055 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:51:45.055 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:51:45.055 [org.springframework.kafka.KafkaListenerEndpointContainer#10-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:51:45.055 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:51:45.055 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:51:45.055 [org.springframework.kafka.KafkaListenerEndpointContainer#10-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:51:45.055 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:51:45.057 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:51:45.057 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:51:45.057 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:51:45.057 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:51:45.068 [org.springframework.kafka.KafkaListenerEndpointContainer#8-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-11-20 19:51:45.069 [org.springframework.kafka.KafkaListenerEndpointContainer#8-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-11-20 19:51:45.069 [org.springframework.kafka.KafkaListenerEndpointContainer#8-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-11-20 19:51:45.069 [org.springframework.kafka.KafkaListenerEndpointContainer#8-1-C-1] [] INFO  o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-11-20 19:51:45.078 [org.springframework.kafka.KafkaListenerEndpointContainer#9-2-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-orders-consumer-group-10 unregistered
2025-11-20 19:51:45.082 [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-group-1-18 unregistered
2025-11-20 19:51:45.085 [org.springframework.kafka.KafkaListenerEndpointContainer#9-1-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-orders-consumer-group-9 unregistered
2025-11-20 19:51:45.087 [org.springframework.kafka.KafkaListenerEndpointContainer#10-1-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-test-consumer-group-26 unregistered
2025-11-20 19:51:45.089 [org.springframework.kafka.KafkaListenerEndpointContainer#8-2-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-messages-consumer-group-7 unregistered
2025-11-20 19:51:45.090 [org.springframework.kafka.KafkaListenerEndpointContainer#2-1-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-detailed-consumer-group-12 unregistered
2025-11-20 19:51:45.093 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dlt-consumer-group-1 unregistered
2025-11-20 19:51:45.095 [org.springframework.kafka.KafkaListenerEndpointContainer#10-0-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-test-consumer-group-25 unregistered
2025-11-20 19:51:45.095 [org.springframework.kafka.KafkaListenerEndpointContainer#9-0-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-orders-consumer-group-8 unregistered
2025-11-20 19:51:45.096 [org.springframework.kafka.KafkaListenerEndpointContainer#8-1-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-messages-consumer-group-6 unregistered
2025-11-20 19:51:45.096 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-detailed-consumer-group-11 unregistered
2025-11-20 19:51:45.097 [org.springframework.kafka.KafkaListenerEndpointContainer#2-2-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-detailed-consumer-group-13 unregistered
2025-11-20 19:51:45.097 [org.springframework.kafka.KafkaListenerEndpointContainer#6-1-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dlt-consumer-group-2 unregistered
2025-11-20 19:51:45.097 [org.springframework.kafka.KafkaListenerEndpointContainer#10-2-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-test-consumer-group-27 unregistered
2025-11-20 19:51:45.098 [org.springframework.kafka.KafkaListenerEndpointContainer#3-1-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-group-2-15 unregistered
2025-11-20 19:51:45.098 [org.springframework.kafka.KafkaListenerEndpointContainer#5-2-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-group-1-20 unregistered
2025-11-20 19:51:45.098 [org.springframework.kafka.KafkaListenerEndpointContainer#8-0-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-messages-consumer-group-5 unregistered
2025-11-20 19:51:45.098 [org.springframework.kafka.KafkaListenerEndpointContainer#6-2-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-dlt-consumer-group-3 unregistered
2025-11-20 19:51:45.098 [org.springframework.kafka.KafkaListenerEndpointContainer#5-1-C-1] [] INFO  o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-group-1-19 unregistered
